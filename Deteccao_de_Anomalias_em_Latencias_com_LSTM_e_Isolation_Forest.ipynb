{
 "cells": [
  {
   "cell_type": "raw",
   "id": "3bb76911-c9ca-4c32-9647-ddc3bd62f023",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Detecção de Anomalias em Dados de Latência Usando CNN-LSTM\n",
    "\n",
    "Este projeto foca na detecção de anomalias em dados de latência de serviços utilizando um modelo híbrido de Rede Neural Convolucional (CNN) e Memória de Longo e Curto Prazo (LSTM). Os dados são analisados, pré-processados e, em seguida, alimentados no modelo CNN-LSTM para detecção de anomalias. As anomalias são categorizadas em \"Normal\", \"Anomalia Possível\" e \"Anomalia Severa\" baseadas nos valores de latência.\n",
    "\n",
    "Pré-requisitos\n",
    "\n",
    "Antes de executar este projeto, certifique-se de ter instalado:\n",
    "\n",
    "Python 3.x\n",
    "Pandas\n",
    "NumPy\n",
    "Scikit-learn\n",
    "TensorFlow\n",
    "Plotly\n",
    "Você pode instalar as bibliotecas necessárias usando o seguinte comando:\n",
    "\n",
    "\n",
    "pip install pandas numpy scikit-learn tensorflow plotly\n",
    "Conjunto de Dados\n",
    "\n",
    "O conjunto de dados utilizado neste projeto deve ser um arquivo Excel contendo dados de latência por serviço. O arquivo deve ter pelo menos uma coluna chamada 'latencies' com valores de latência separados por vírgula.\n",
    "\n",
    "Uso\n",
    "\n",
    "Coloque seu conjunto de dados no mesmo diretório do script e nomeie-o latencies by service.xlsx.\n",
    "Execute o script usando um interpretador Python.\n",
    "O script realiza as seguintes operações:\n",
    "\n",
    "Carrega e pré-processa os dados de latência do arquivo Excel.\n",
    "Divide os dados de latência em normal, possíveis anomalias e anomalias severas, baseado em percentis de latência.\n",
    "Aplica técnicas de engenharia de recursos para preparar os dados para o modelo CNN-LSTM.\n",
    "Treina um modelo CNN-LSTM nos dados pré-processados.\n",
    "Avalia a performance do modelo em um conjunto de teste.\n",
    "Salva o modelo treinado.\n",
    "Visualiza as latências categorizadas usando Plotly.\n",
    "Funcionalidades\n",
    "\n",
    "Pré-processamento de Dados: Converte dados brutos de latência em um formato estruturado, calcula média móvel e desvio padrão, e normaliza os recursos.\n",
    "Detecção de Anomalias: Categoriza as latências em diferentes níveis de anomalias usando limiares de percentil.\n",
    "Modelo CNN-LSTM: Combina camadas Conv1D e LSTM para capturar padrões espaciais e temporais nos dados.\n",
    "Avaliação e Visualização do Modelo: Avalia a performance do modelo e visualiza as latências categorizadas.\n",
    "Saída\n",
    "\n",
    "Após a execução do script, a performance do modelo (perda e precisão) será impressa no console. Além disso, uma figura Plotly mostrando as latências categorizadas será exibida.\n",
    "\n",
    "Salvamento do Modelo\n",
    "\n",
    "O modelo CNN-LSTM treinado é salvo em cnn_lstm_anomaly_detection_model.h5, permitindo seu uso futuro sem necessidade de re-treinamento.\n",
    "\n",
    "Visualização\n",
    "\n",
    "O script gera um gráfico Plotly que categoriza as latências em \"Normal\", \"Anomalia Possível\" e \"Anomalia Severa\". Este auxílio visual ajuda a entender a distribuição e a natureza das anomalias no conjunto de dados.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce182b9-964c-4141-b622-42e18cdadfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, Conv1D, MaxPooling1D, Flatten\n",
    "from sklearn.model_selection import train_test_split\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Carregar os dados do arquivo Excel\n",
    "file_path = 'latencies by service.xlsx'\n",
    "df = pd.read_excel(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72d265a-4fe6-42ef-bb85-336486e01682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversão das latências em uma lista de números e reset do índice\n",
    "df_exploded = df['latencies'].str.split(',', expand=True).stack().astype(int).reset_index(name='latency')\n",
    "df_exploded.drop('level_1', axis=1, inplace=True)\n",
    "\n",
    "# Calcular os percentis para as latências\n",
    "percentil_90 = np.percentile(df_exploded['latency'], 90)\n",
    "percentil_95 = np.percentile(df_exploded['latency'], 95)\n",
    "\n",
    "# Função para categorizar latências\n",
    "def categorize_latency(latency):\n",
    "    if latency > percentil_95:\n",
    "        return 'Severe Anomaly'\n",
    "    elif latency > percentil_90:\n",
    "        return 'Possible Anomaly'\n",
    "    else:\n",
    "        return 'Normal'\n",
    "\n",
    "df_exploded['category'] = df_exploded['latency'].apply(categorize_latency)\n",
    "\n",
    "# Engenharia de features\n",
    "window_size = 5\n",
    "df_exploded['rolling_mean'] = df_exploded['latency'].rolling(window=window_size).mean()\n",
    "df_exploded['rolling_std'] = df_exploded['latency'].rolling(window=window_size).std()\n",
    "\n",
    "# Removendo os valores NaN gerados pela função rolling\n",
    "df_exploded.dropna(inplace=True)\n",
    "\n",
    "# Normalização dos dados\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(df_exploded[['latency', 'rolling_mean', 'rolling_std']])\n",
    "\n",
    "# Formatação dos dados para entrada na CNN + LSTM ([samples, time steps, features])\n",
    "X = np.array([scaled_features[i-window_size:i] for i in range(window_size, len(scaled_features))])\n",
    "y = df_exploded['category'][window_size:].map({'Normal': 0, 'Possible Anomaly': 1, 'Severe Anomaly': 2}).values\n",
    "\n",
    "# Divisão em conjuntos de treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb8d76d-0dae-415d-88c9-ce4275ce57cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Construção do modelo com CNN + LSTM\n",
    "model = Sequential()\n",
    "\n",
    "# Camada Conv1D\n",
    "model.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(window_size, X.shape[2])))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "\n",
    "# Camada LSTM\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Camada de saída\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# Compilando o modelo\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Treinamento do modelo\n",
    "model.fit(X_train, y_train, epochs=40, batch_size=32, validation_data=(X_test, y_test), verbose=1)\n",
    "\n",
    "# Avaliação do modelo\n",
    "performance = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Test Loss: {performance[0]}, Test Accuracy: {performance[1]}')\n",
    "\n",
    "# Salvando o modelo treinado\n",
    "model.save('cnn_lstm_anomaly_detection_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d7815c-ec7b-4723-be00-15012e76b031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualização das categorias de latência com Plotly\n",
    "fig = go.Figure()\n",
    "\n",
    "# Adicionando as latências normais\n",
    "fig.add_trace(go.Scatter(x=df_exploded[df_exploded['category'] == 'Normal'].index, \n",
    "                         y=df_exploded[df_exploded['category'] == 'Normal']['latency'],\n",
    "                         mode='markers',\n",
    "                         name='Normal',\n",
    "                         marker=dict(color='blue')))\n",
    "\n",
    "# Adicionando as possíveis anomalias\n",
    "fig.add_trace(go.Scatter(x=df_exploded[df_exploded['category'] == 'Possible Anomaly'].index, \n",
    "                         y=df_exploded[df_exploded['category'] == 'Possible Anomaly']['latency'],\n",
    "                         mode='markers',\n",
    "                         name='Possible Anomaly',\n",
    "                         marker=dict(color='green')))\n",
    "\n",
    "# Adicionando as anomalias severas\n",
    "fig.add_trace(go.Scatter(x=df_exploded[df_exploded['category'] == 'Severe Anomaly'].index, \n",
    "                         y=df_exploded[df_exploded['category'] == 'Severe Anomaly']['latency'],\n",
    "                         mode='markers',\n",
    "                         name='Severe Anomaly',\n",
    "                         marker=dict(color='red')))\n",
    "\n",
    "fig.update_layout(title='Latências Categorizadas',\n",
    "                  xaxis_title='Índice',\n",
    "                  yaxis_title='Latência',\n",
    "                  legend_title='Categoria')\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
