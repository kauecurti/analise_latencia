{
 "cells": [
  {
   "cell_type": "raw",
   "id": "3bb76911-c9ca-4c32-9647-ddc3bd62f023",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Análise de Latências e Detecção de Anomalias\n",
    "\n",
    "Descrição\n",
    "\n",
    "Este projeto implementa um pipeline completo de análise de dados, engenharia de recursos, normalização, e modelagem preditiva para identificar anomalias em latências de redes utilizando Python. A análise inicia com a extração de dados, seguida por uma transformação detalhada do conjunto de dados, e culmina na detecção de anomalias usando uma combinação de CNN (Convolutional Neural Network) e LSTM (Long Short-Term Memory).\n",
    "\n",
    "Pipeline\n",
    "\n",
    "Preparação dos Dados\n",
    "Extração de Dados: Inicia com a consulta de latências armazenadas em um banco de dados SQL, seguida pela configuração do cliente do Google BigQuery para extração e carga de dados.\n",
    "Transformação: df_dw['latencies'] é dividido em múltiplos registros usando .str.split(), transformado em um DataFrame com .stack(), e convertido para inteiros. As colunas irrelevantes são removidas.\n",
    "Análise Exploratória e Engenharia de Recursos\n",
    "Cálculo de Percentis: Calcula os percentis 90 e 95 das latências para identificar possíveis anomalias.\n",
    "Categorização: As latências são categorizadas em \"Normal\", \"Possible Anomaly\", ou \"Severe Anomaly\" baseadas nos percentis calculados.\n",
    "Engenharia de Recursos: Calcula a média e o desvio padrão móvel das latências para incorporar contexto temporal nos dados.\n",
    "Normalização e Preparação dos Dados para Modelagem\n",
    "Normalização: Os dados são normalizados usando StandardScaler para adequação ao modelo de aprendizado de máquina.\n",
    "Preparação para CNN + LSTM: Os dados são reformatados para se ajustarem à entrada esperada por uma rede neural combinando CNN e LSTM, segmentando os dados em janelas temporais.\n",
    "Modelagem e Avaliação\n",
    "Construção do Modelo: Um modelo sequencial combinando CNN para extração de características e LSTM para capturar dependências temporais é construído e compilado.\n",
    "Treinamento: O modelo é treinado usando os dados preparados, com validação em um conjunto de testes para monitorar a generalização.\n",
    "Avaliação: Performance do modelo é avaliada usando perda e acurácia no conjunto de teste.\n",
    "Visualização de Resultados\n",
    "Plotly: Utiliza Plotly para visualizar as categorias de latência no conjunto de dados, permitindo uma análise intuitiva da distribuição das anomalias.\n",
    "Requisitos\n",
    "\n",
    "pandas\n",
    "numpy\n",
    "sklearn\n",
    "tensorflow\n",
    "plotly\n",
    "google-cloud-bigquery\n",
    "Uso\n",
    "\n",
    "Para executar este pipeline, é necessário configurar corretamente as credenciais do Google Cloud e garantir que todos os pacotes necessários estejam instalados. O código pode ser executado em um ambiente Python com suporte às bibliotecas mencionadas.\n",
    "\n",
    "Salvamento e Carregamento do Modelo\n",
    "\n",
    "O modelo treinado é salvo no disco, permitindo reutilização futura sem a necessidade de re-treinamento. O carregamento do modelo pode ser feito utilizando a API do Keras.\n",
    "\n",
    "Visualização de Dados\n",
    "\n",
    "A visualização final das categorias de latência fornece insights imediatos sobre a presença e distribuição de anomalias no conjunto de dados, facilitando a tomada de decisão baseada em dados.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfae1ad-d3f9-4280-89b5-62124b38c81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Carregar dados\n",
    "df = pd.read_excel('latencies by service.xlsx')\n",
    "\n",
    "# Conectar ao banco de dados transacional\n",
    "engine = create_engine('postgresql://postgres:1234@localhost:5432/postgres')\n",
    "df.to_sql('latencias', con=engine, if_exists='replace', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b830ab-44d5-4a72-b628-879a3ddf0573",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT * FROM latencias\"\n",
    "df_transacional = pd.read_sql(query, con=engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51bbd5a-8d1f-4bf0-a3a3-4b25e18326fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.cloud import bigquery\n",
    "\n",
    "# Caminho para o seu arquivo de credenciais\n",
    "credential_path = \"testechave.json\"\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = credential_path\n",
    "\n",
    "# Configuração do cliente BigQuery\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Substitua pelo ID da tabela adequado\n",
    "table_id = \"teste.teste2\"\n",
    "\n",
    "# Carregar DataFrame no BigQuery\n",
    "job = client.load_table_from_dataframe(df_transacional, table_id)\n",
    "job.result()\n",
    "\n",
    "print(\"Carregamento concluído.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b30d658-2ba5-475b-bc32-2a165713992f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo de extração de dados do BigQuery para um DataFrame\n",
    "query = \"SELECT * FROM `teste.teste2` WHERE TRUE\"\n",
    "df_dw = client.query(query).to_dataframe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce182b9-964c-4141-b622-42e18cdadfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, Conv1D, MaxPooling1D, Flatten\n",
    "from sklearn.model_selection import train_test_split\n",
    "import plotly.graph_objects as go\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72d265a-4fe6-42ef-bb85-336486e01682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usaremos df_dw diretamente\n",
    "df_exploded = df_dw['latencies'].str.split(',', expand=True).stack().astype(int).reset_index(name='latency')\n",
    "df_exploded.drop('level_1', axis=1, inplace=True)\n",
    "\n",
    "# O resto do código permanece praticamente o mesmo\n",
    "\n",
    "# Calcular os percentis para as latências\n",
    "percentil_90 = np.percentile(df_exploded['latency'], 90)\n",
    "percentil_95 = np.percentile(df_exploded['latency'], 95)\n",
    "\n",
    "# Função para categorizar latências\n",
    "def categorize_latency(latency):\n",
    "    if latency > percentil_95:\n",
    "        return 'Severe Anomaly'\n",
    "    elif latency > percentil_90:\n",
    "        return 'Possible Anomaly'\n",
    "    else:\n",
    "        return 'Normal'\n",
    "\n",
    "df_exploded['category'] = df_exploded['latency'].apply(categorize_latency)\n",
    "\n",
    "# Engenharia de features\n",
    "window_size = 5\n",
    "df_exploded['rolling_mean'] = df_exploded['latency'].rolling(window=window_size).mean()\n",
    "df_exploded['rolling_std'] = df_exploded['latency'].rolling(window=window_size).std()\n",
    "\n",
    "# Removendo os valores NaN gerados pela função rolling\n",
    "df_exploded.dropna(inplace=True)\n",
    "\n",
    "# Normalização dos dados\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(df_exploded[['latency', 'rolling_mean', 'rolling_std']])\n",
    "\n",
    "# Formatação dos dados para entrada na CNN + LSTM ([samples, time steps, features])\n",
    "X = np.array([scaled_features[i-window_size:i] for i in range(window_size, len(scaled_features))])\n",
    "y = df_exploded['category'][window_size:].map({'Normal': 0, 'Possible Anomaly': 1, 'Severe Anomaly': 2}).values\n",
    "\n",
    "# Divisão em conjuntos de treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb8d76d-0dae-415d-88c9-ce4275ce57cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Construção do modelo com CNN + LSTM\n",
    "model = Sequential()\n",
    "\n",
    "# Camada Conv1D\n",
    "model.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(window_size, X.shape[2])))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "\n",
    "# Camada LSTM\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Camada de saída\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# Compilando o modelo\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Treinamento do modelo\n",
    "model.fit(X_train, y_train, epochs=40, batch_size=32, validation_data=(X_test, y_test), verbose=1)\n",
    "\n",
    "# Avaliação do modelo\n",
    "performance = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Test Loss: {performance[0]}, Test Accuracy: {performance[1]}')\n",
    "\n",
    "# Salvando o modelo treinado\n",
    "model.save('cnn_lstm_anomaly_detection_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d7815c-ec7b-4723-be00-15012e76b031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualização das categorias de latência com Plotly\n",
    "fig = go.Figure()\n",
    "\n",
    "# Adicionando as latências normais\n",
    "fig.add_trace(go.Scatter(x=df_exploded[df_exploded['category'] == 'Normal'].index, \n",
    "                         y=df_exploded[df_exploded['category'] == 'Normal']['latency'],\n",
    "                         mode='markers',\n",
    "                         name='Normal',\n",
    "                         marker=dict(color='blue')))\n",
    "\n",
    "# Adicionando as possíveis anomalias\n",
    "fig.add_trace(go.Scatter(x=df_exploded[df_exploded['category'] == 'Possible Anomaly'].index, \n",
    "                         y=df_exploded[df_exploded['category'] == 'Possible Anomaly']['latency'],\n",
    "                         mode='markers',\n",
    "                         name='Possible Anomaly',\n",
    "                         marker=dict(color='green')))\n",
    "\n",
    "# Adicionando as anomalias severas\n",
    "fig.add_trace(go.Scatter(x=df_exploded[df_exploded['category'] == 'Severe Anomaly'].index, \n",
    "                         y=df_exploded[df_exploded['category'] == 'Severe Anomaly']['latency'],\n",
    "                         mode='markers',\n",
    "                         name='Severe Anomaly',\n",
    "                         marker=dict(color='red')))\n",
    "\n",
    "fig.update_layout(title='Latências Categorizadas',\n",
    "                  xaxis_title='Índice',\n",
    "                  yaxis_title='Latência',\n",
    "                  legend_title='Categoria')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39af167b-d597-473c-b948-25116b136237",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
